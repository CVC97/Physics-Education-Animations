{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.0.post0</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.0\u001b[0m\u001b[32m.post0\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter Capture Output v0.0.11\n"
     ]
    }
   ],
   "source": [
    "from manim import *\n",
    "import jupyter_capture_output\n",
    "\n",
    "video_scene = \" -v WARNING --progress_bar None --disable_caching et3_Scene\"\n",
    "image_scene = f\" -v WARNING --progress_bar None --disable_caching -r {2*427},{2*240}  -s et3_Scene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLAR_PUPIL_BASE = (0.05, 3/4*PI)\n",
    "\n",
    "\n",
    "def screen2polar(x, y):\n",
    "    ppb_radius = POLAR_PUPIL_BASE[0]\n",
    "    ppb_angle = POLAR_PUPIL_BASE[1]\n",
    "\n",
    "    correction = 0.8/np.sqrt(5)\n",
    "    cart_pupil = np.array([ppb_radius*np.cos(ppb_angle) + correction*x, ppb_radius*np.sin(ppb_angle) + correction*y, 0])\n",
    "\n",
    "    radius = np.sqrt(cart_pupil[0]**2 + cart_pupil[1]**2)\n",
    "    angle = np.arctan2(cart_pupil[1], cart_pupil[0])\n",
    "    return (radius, angle)\n",
    "\n",
    "\n",
    "def screen_path(t):\n",
    "    if t < np.sqrt(2):\n",
    "        t /= np.sqrt(2)\n",
    "        return (-2*t, t)\n",
    "    elif t < np.sqrt(2) + 2:\n",
    "        t -= np.sqrt(2)\n",
    "        return (-2, 1-t)\n",
    "    elif t < np.sqrt(2) + 2 + 4:\n",
    "        t -= np.sqrt(2) + 2\n",
    "        return (-2 + t, -1)\n",
    "    elif t < np.sqrt(2) + 2 + 4 + 2:\n",
    "        t -= np.sqrt(2) + 2 + 4\n",
    "        return (2, -1 + t)\n",
    "    elif t < 2*np.sqrt(2) + 2 + 4 + 2:\n",
    "        t -= np.sqrt(2) + 2 + 4 + 2\n",
    "        t /= np.sqrt(2)\n",
    "        return (2-2*t, 1-t)\n",
    "    else:\n",
    "        return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eye(VMobject):\n",
    "    def __init__(self, position, size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eye_center = position\n",
    "        self.eye_radius = size\n",
    "        circle = Circle(radius = self.eye_radius, color = GREY, stroke_width = 15).move_to(self.eye_center)\n",
    "        circle.z_index = 2\n",
    "        bg_white = Circle(radius = 2*self.eye_radius, color = WHITE, stroke_width = 440*self.eye_radius/2.15).move_to(self.eye_center)\n",
    "        bg_white.z_index = 0.5\n",
    "        self.add(circle, bg_white)\n",
    "\n",
    "    # returns the pupil\n",
    "    def get_pupil(self, pupil_size, pupil_pradius, pupil_angle, overextension_radius = 1):\n",
    "        pupil_radius = pupil_pradius * (self.eye_radius - pupil_size) / 4\n",
    "        # pupil_radius = 1 *  (self.eye_radius - pupil_size)\n",
    "        self.pupil_center = self.eye_center + np.array([pupil_radius*np.cos(pupil_angle), pupil_radius*np.sin(pupil_angle), 0])\n",
    "        pupil_circle = Circle(radius = pupil_size, fill_opacity = 1).move_to(self.pupil_center).set_color(BLACK)\n",
    "        pupil_circle.z_index = 1\n",
    "        pupil_group = VGroup(pupil_circle)\n",
    "        for i in range(36):\n",
    "            pupil_group.add(Line(start = self.pupil_center, end = self.pupil_center + overextension_radius*UP*self.eye_radius).rotate(about_point = self.pupil_center, angle = 10*i*2*PI/360).set_color([GREY, LIGHTER_GREY, GREY]))\n",
    "        return pupil_group\n",
    "    \n",
    "    # returns cornea reflection\n",
    "    def get_reflection(self, reflect_pradius, reflect_angle):\n",
    "        reflect_radius = reflect_pradius * self.eye_radius\n",
    "        self.reflect_center = self.eye_center + np.array([reflect_radius*np.cos(reflect_angle), reflect_radius*np.sin(reflect_angle), 0])\n",
    "        reflect_dot = Dot(point = self.reflect_center, radius = 0.1, fill_opacity = 0.8).set_color([PURE_RED, RED])\n",
    "        reflect_dot.z_index = 3\n",
    "        cross_length = 0.75\n",
    "        reflect_horizontal = Line(start = self.reflect_center - cross_length*RIGHT, end = self.reflect_center + cross_length*RIGHT, stroke_width = 2, color = RED)\n",
    "        reflect_horizontal.z_index = 3\n",
    "        reflect_vertical = Line(start = self.reflect_center - cross_length*UP, end = self.reflect_center + cross_length*UP, stroke_width = 2, color = RED)\n",
    "        reflect_vertical.z_index = 3\n",
    "        return VGroup(reflect_dot, reflect_horizontal, reflect_vertical)\n",
    "        #return reflect_dot\n",
    "    \n",
    "    def get_connector(self):\n",
    "        connect_vector = Line(start = self.reflect_center, end = self.pupil_center, color = BLUE).add_tip(tip_length = 0.125, tip_width = 0.125)\n",
    "        connect_vector.z_index = 3.5\n",
    "        connect_vector.tip.z_index = 3.5\n",
    "        return connect_vector\n",
    "\n",
    "\n",
    "class Screen(VMobject):\n",
    "    def __init__(self, position, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.npla = NumberPlane(x_range = [-2, 2, 1], y_range = [-1, 1, 0.5], x_length = width*0.8, y_length = height*0.8).move_to(position)\n",
    "        #self.add(npla)\n",
    "        rectangle = Rectangle(height = height, width = width, stroke_width = 4, color = BLACK).move_to(position)\n",
    "        rectangle.z_index = 1\n",
    "        self.add(rectangle)\n",
    "\n",
    "        dot_center = Dot(self.npla.c2p(0, 0, 0), radius = 0.1, color = GREY)\n",
    "        dot_center.z_index = 1\n",
    "        dot_top_left = Dot(self.npla.c2p(-2, 1, 0), radius = 0.1, color = GREY)\n",
    "        dot_top_left.z_index = 1\n",
    "        dot_bottom_left = Dot(self.npla.c2p(-2, -1, 0), radius = 0.1, color = GREY)\n",
    "        dot_bottom_left.z_index = 1\n",
    "        dot_bottom_right = Dot(self.npla.c2p(2, -1, 0), radius = 0.1, color = GREY)\n",
    "        dot_bottom_right.z_index = 1\n",
    "        dot_top_right = Dot(self.npla.c2p(2, 1, 0), radius = 0.1, color = GREY)\n",
    "        dot_top_right.z_index = 1\n",
    "        self.add(dot_center, dot_top_left, dot_bottom_left, dot_bottom_right, dot_top_right)\n",
    "\n",
    "    \n",
    "    def get_viewpoint(self, x, y):\n",
    "        dot_viewpoint = Dot(self.npla.c2p(x, y, 0), radius = 0.075, color = RED, fill_opacity = 0.75)\n",
    "        dot_viewpoint.z_index = 1\n",
    "        return dot_viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved by overwring previous file at animations/eye_tracking_3/eye_tracking_3_START_CLEAN.mp4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/et3_Scene@2024-10-25@12-11-44.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%capture_video --path \"animations/eye_tracking_3/eye_tracking_3_START_CLEAN.mp4\"\n",
    "%%manim -qh --fps 60 $video_scene\n",
    "\n",
    "\n",
    "class et3_Scene(Scene):\n",
    "    def construct(self):\n",
    "        self.camera.background_color = WHITE\n",
    "\n",
    "        # human eye to graphic transition\n",
    "        human_eye = ImageMobject(\"external_media/Eye1.jpg\")\n",
    "        self.add(human_eye)\n",
    "\n",
    "        eye = Eye(position = np.array([0, 0.25, 0]), size = 2.15)\n",
    "        pupil = eye.get_pupil(pupil_size = 0.38, pupil_pradius = POLAR_PUPIL_BASE[0], pupil_angle = POLAR_PUPIL_BASE[1])\n",
    "        cornea_reflection = eye.get_reflection(reflect_pradius = 0.5, reflect_angle = 7/4*PI)\n",
    "        vector = eye.get_connector()\n",
    "\n",
    "        eye2 = Eye(position = np.array([0, 0.25, 0] + 4*LEFT), size = 2.15*0.5)\n",
    "        pupil2 = eye2.get_pupil(pupil_size = 0.38*0.5, pupil_pradius = POLAR_PUPIL_BASE[0], pupil_angle = POLAR_PUPIL_BASE[1])\n",
    "        cornea_reflection2 = eye2.get_reflection(reflect_pradius = 0.5, reflect_angle = 7/4*PI).scale(0.5)\n",
    "        vector2 = eye2.get_connector()\n",
    "\n",
    "        # eye tracking calibration\n",
    "        screen = Screen(position = np.array([2, 0.25, 0]), height = 5*0.8, width = 8*0.8)\n",
    "        viewpoint = screen.get_viewpoint(0, 0)\n",
    "\n",
    "        # MAIN\n",
    "        self.add(eye)\n",
    "        self.wait(1.5)\n",
    "        self.play(FadeIn(pupil), FadeOut(human_eye), run_time = 3)\n",
    "        self.wait(0.5)\n",
    "        self.play(FadeIn(cornea_reflection), run_time = 3)\n",
    "        self.play(Create(vector), run_time = 1.5)\n",
    "        self.wait(1.5)\n",
    "\n",
    "        self.play(FadeTransform(eye, eye2), FadeTransform(pupil, pupil2), FadeTransform(cornea_reflection, cornea_reflection2), FadeTransform(vector, vector2), run_time = 1.5)\n",
    "        self.wait(1.5)\n",
    "\n",
    "        self.play(Create(screen), run_time = 4.5)\n",
    "        self.wait(0.5)\n",
    "        self.play(FadeIn(viewpoint), run_time = 1.5)\n",
    "        self.wait(1.5)\n",
    "\n",
    "        # self.add(eye)\n",
    "        # self.add(pupil, eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved by overwring previous file at animations/eye_tracking_3/eye_tracking_3_CALIBRATION.mp4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/et3_Scene@2024-10-24@14-26-29.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%capture_video --path \"animations/eye_tracking_3/eye_tracking_3_CALIBRATION.mp4\"\n",
    "%%manim -qh --fps 60 $video_scene\n",
    "\n",
    "\n",
    "class et3_Scene(Scene):\n",
    "    def construct(self):\n",
    "        self.camera.background_color = WHITE\n",
    "\n",
    "\n",
    "        eye = Eye(position = np.array([0, 0.25, 0] + 4*LEFT), size = 2.15*0.5)\n",
    "        self.add(eye)\n",
    "\n",
    "        pupil = eye.get_pupil(pupil_size = 0.38*0.5, pupil_pradius = POLAR_PUPIL_BASE[0], pupil_angle = POLAR_PUPIL_BASE[1], overextension_radius = 1.2)\n",
    "        self.add(pupil)\n",
    "\n",
    "        cornea_reflection = eye.get_reflection(reflect_pradius = 0.5, reflect_angle = 7/4*PI).scale(0.5)\n",
    "        self.add(cornea_reflection)\n",
    "\n",
    "        vector = eye.get_connector()\n",
    "        self.add(vector)\n",
    "\n",
    "\n",
    "        # eye tracking calibration\n",
    "        screen = Screen(position = np.array([2, 0.25, 0]), height = 5*0.8, width = 8*0.8)\n",
    "        self.add(screen)\n",
    "\n",
    "        viewpoint = screen.get_viewpoint(0, 0)\n",
    "        self.add(viewpoint)\n",
    "        \n",
    "        \n",
    "        def viewpoint_updater(point):\n",
    "            t = t_tracker.get_value()\n",
    "            x, y = screen_path(t)\n",
    "            rradius, angle = screen2polar(x, y)\n",
    "\n",
    "            point.become(screen.get_viewpoint(x, y))\n",
    "\n",
    "        def pupil_updater(pupil):\n",
    "            t = t_tracker.get_value()\n",
    "            x, y = screen_path(t)\n",
    "            rradius, angle = screen2polar(x, y)\n",
    "\n",
    "            pupil.become(eye.get_pupil(pupil_size = 0.38*0.5, pupil_pradius = rradius, pupil_angle = angle))\n",
    "            vector.become(eye.get_connector())  \n",
    "\n",
    "\n",
    "        # CALIBRATION ANIMATION\n",
    "        t_tracker = ValueTracker(0)\n",
    "        viewpoint.add_updater(viewpoint_updater)\n",
    "        pupil.add_updater(pupil_updater)\n",
    "        self.play(t_tracker.animate.set_value(12), rate_func = linear, run_time = 10)\n",
    "        self.wait(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system('ffmpeg -f concat -i eye_tracking_3_merge_list.txt -c copy eye_tracking_3_CLEAN_TRANSITION_1.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_per",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
